{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center>Intelligent Analysis of Medical Images</center></h3>\n",
    "<h4><center>HW 2: Practical Part</center></h4>\n",
    "<table width='100%' style=\"border: none;\">\n",
    "    <tr style=\"border: none; text-align: center;\">\n",
    "        <td style=\"border: none;\"><h5>Javad Razi</h5></td>\n",
    "        <td style=\"border: none;\"><h5>401204354</h5></td>\n",
    "</table>\n",
    "<hr/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part A**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Import Libraries\n",
    "In this cell, we will install, and import all the necessary libraries required for the implementation. This includes `torch` for model building and training, `torchvision` for datasets and data transforms, and additional libraries for metrics and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import gdown\n",
    "except:\n",
    "    %pip install gdown\n",
    "    \n",
    "try:\n",
    "    import torch\n",
    "except:\n",
    "    %pip install torch\n",
    "\n",
    "try:\n",
    "    import torchvision\n",
    "except:\n",
    "    %pip install torchvision\n",
    "    \n",
    "try:\n",
    "    import pickle\n",
    "except:\n",
    "    %pip install pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tools\\Anaconda3\\envs\\llm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\jrazi\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\projections\\__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists('./datasets'):\n",
    "    os.makedirs('./datasets')\n",
    "\n",
    "# List of file IDs\n",
    "file_ids = ['1i9Ei3QSmPBnYzqknvZPg_6TNsPomxQYG', '1-2cN6EuFQnIM53q1N3MQCVcoid1NPBWk', '1-0bl_TuSM-JQ4nCwAW7ySn3uYMAGlaz4']\n",
    "\n",
    "# Download the files\n",
    "for file_id in file_ids:\n",
    "    url = f'https://drive.google.com/uc?id={file_id}'\n",
    "    output = f'./datasets/{file_id}.pickle'\n",
    "    if not os.path.exists(output):\n",
    "        gdown.download(url, output, quiet=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load The Pickle Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./datasets/train.pickle', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open('./datasets/test.pickle', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "with open('./datasets/validation.pickle', 'rb') as f:\n",
    "    validation_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet Architecture\n",
    "Here we define the AlexNet architecture in PyTorch. We create a class `AlexNet` that inherits from `nn.Module` and define all the layers in the `__init__` method. The `forward` method dictates the data flow through the network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jrazi\\Desktop\\repo\\medical-image-processing-fall-2023\\HW2\\practical_alexnet.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jrazi/Desktop/repo/medical-image-processing-fall-2023/HW2/practical_alexnet.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mAlexNet\u001b[39;00m(nn\u001b[39m.\u001b[39mModule):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jrazi/Desktop/repo/medical-image-processing-fall-2023/HW2/practical_alexnet.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, num_classes\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jrazi/Desktop/repo/medical-image-processing-fall-2023/HW2/practical_alexnet.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39msuper\u001b[39m(AlexNet, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Dataloaders\n",
    "In this cell, we define our custom dataset class which will handle the MRI images. We'll also create the dataloaders for training, validation, and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.data[index]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Define transforms for the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((227, 227)), # AlexNet uses 227x227 inputs\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = MRIDataset(train_data, transform=transform)\n",
    "valid_dataset = MRIDataset(validation_data, transform=transform)\n",
    "test_dataset = MRIDataset(test_data, transform=transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function and Optimizer\n",
    "In this cell, we define the loss function and the optimizer for our AlexNet model. We use Cross-Entropy Loss for our multi-class classification problem and the Adam optimizer with a learning rate of 1e-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet(num_classes=3)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop\n",
    "Here we define the training loop where we train our AlexNet model. We keep track of the loss and accuracy for both the training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jrazi\\Desktop\\repo\\medical-image-processing-fall-2023\\HW2\\practical_alexnet.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jrazi/Desktop/repo/medical-image-processing-fall-2023/HW2/practical_alexnet.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Training parameters\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jrazi/Desktop/repo/medical-image-processing-fall-2023/HW2/practical_alexnet.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jrazi/Desktop/repo/medical-image-processing-fall-2023/HW2/practical_alexnet.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_steps \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_loader)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jrazi/Desktop/repo/medical-image-processing-fall-2023/HW2/practical_alexnet.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m valid_steps \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(valid_loader)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jrazi/Desktop/repo/medical-image-processing-fall-2023/HW2/practical_alexnet.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# To track the training loss as the model trains\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "num_epochs = 10\n",
    "train_steps = len(train_loader)\n",
    "valid_steps = len(valid_loader)\n",
    "\n",
    "# To track the training loss as the model trains\n",
    "train_losses = []\n",
    "# To track the validation loss as the model trains\n",
    "valid_losses = []\n",
    "# To track the average training loss per epoch as the model trains\n",
    "avg_train_losses = []\n",
    "# To track the average validation loss per epoch as the model trains\n",
    "avg_valid_losses = [] \n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_train_loss = 0\n",
    "    total_valid_loss = 0\n",
    "\n",
    "    # Training\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()  # Set model to evaluate mode\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            total_valid_loss += loss.item()\n",
    "\n",
    "    # Calculate average losses\n",
    "    avg_train_loss = total_train_loss / train_steps\n",
    "    avg_valid_loss = total_valid_loss / valid_steps\n",
    "    train_losses.append(avg_train_loss)\n",
    "    valid_losses.append(avg_valid_loss)\n",
    "    \n",
    "    # Print training and validation progress\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Valid Loss: {avg_valid_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation Loss Plots\n",
    "In this cell, we visualize the training and validation loss over the epochs to understand the learning trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.plot(avg_train_losses,label=\"train\")\n",
    "plt.plot(avg_valid_losses,label=\"validation\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Model\n",
    "In this cell, we evaluate the trained AlexNet model on the test dataset and calculate the classification metrics like accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part B**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pre-Trained AlexNet\n",
    "In this cell, we load a pre-trained AlexNet model from torchvision's models. We then replace the final classification layer to match the number of classes in our dataset. We'll also define the loss function and optimizer for this pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# Load pre-trained AlexNet\n",
    "pretrained_alexnet = models.alexnet(pretrained=True)\n",
    "# Modify the classifier to match the number of classes\n",
    "pretrained_alexnet.classifier[6] = nn.Linear(pretrained_alexnet.classifier[6].in_features, 3)\n",
    "pretrained_alexnet = pretrained_alexnet.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(pretrained_alexnet.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Validate Pre-Trained AlexNet\n",
    "Here we train and validate the pre-trained AlexNet on our MRI dataset. We track the loss and accuracy for both the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "num_epochs = 10\n",
    "train_steps = len(train_loader)\n",
    "valid_steps = len(valid_loader)\n",
    "\n",
    "# To track the training loss as the model trains\n",
    "pretrained_train_losses = []\n",
    "# To track the validation loss as the model trains\n",
    "pretrained_valid_losses = []\n",
    "# To track the average training loss per epoch as the model trains\n",
    "pretrained_avg_train_losses = []\n",
    "# To track the average validation loss per epoch as the model trains\n",
    "pretrained_avg_valid_losses = [] \n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    pretrained_alexnet.train()  # Set model to training mode\n",
    "    total_train_loss = 0\n",
    "    total_valid_loss = 0\n",
    "\n",
    "    # Training\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = pretrained_alexnet(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    pretrained_alexnet.eval()  # Set model to evaluate mode\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = pretrained_alexnet(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_valid_loss += loss.item()\n",
    "\n",
    "    # Calculate average losses\n",
    "    avg_train_loss = total_train_loss / train_steps\n",
    "    avg_valid_loss = total_valid_loss / valid_steps\n",
    "    pretrained_train_losses.append(avg_train_loss)\n",
    "    pretrained_valid_losses.append(avg_valid_loss)\n",
    "    \n",
    "    # Print training and validation progress\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Valid Loss: {avg_valid_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Loss and Accuracy for Pre-Trained AlexNet\n",
    "We visualize the training and validation loss and accuracy for the pre-trained AlexNet using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.plot(pretrained_avg_train_losses,label=\"train\")\n",
    "plt.plot(pretrained_avg_valid_losses,label=\"validation\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Pre-Trained AlexNet\n",
    "In this cell, we evaluate the pre-trained AlexNet on the test dataset and calculate the classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "pretrained_alexnet.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = pretrained_alexnet(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of From-Scratch and Pre-Trained AlexNet\n",
    "In this cell, we compare the performance of our from-scratch AlexNet with the pre-trained AlexNet on our dataset, based on the metrics we calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you would calculate and print out a comparison of metrics between the from-scratch and the pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part C**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Supervised Contrastive Loss\n",
    "Here We'll define the new loss function and update our training loop accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.1):\n",
    "        super(SupervisedContrastiveLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        batch_size = features.shape[0]\n",
    "        mask = torch.eye(batch_size).to(features.device)\n",
    "        \n",
    "        # Normalize the features\n",
    "        features = F.normalize(features, dim=1)\n",
    "        \n",
    "        # Compute the similarity matrix\n",
    "        sim_matrix = torch.matmul(features, features.T)\n",
    "        \n",
    "        # Create the positive and negative masks\n",
    "        pos_mask = labels.expand(batch_size, batch_size).eq(labels.expand(batch_size, batch_size).T)\n",
    "        neg_mask = ~pos_mask\n",
    "        \n",
    "        # Compute the loss\n",
    "        pos_sim = sim_matrix[pos_mask & ~mask].view(batch_size, -1)\n",
    "        neg_sim = sim_matrix[neg_mask].view(batch_size, -1)\n",
    "        \n",
    "        pos_loss = torch.sum(-torch.log(F.softmax(pos_sim / self.temperature, dim=1)), dim=1)\n",
    "        neg_loss = torch.sum(torch.log(F.softmax(neg_sim / self.temperature, dim=1)), dim=1)\n",
    "        \n",
    "        loss = pos_loss + neg_loss\n",
    "        return loss.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain & Fine-Tune with Categorical Cross-Entropy\n",
    "Here, we retrain the from-scratch AlexNet using Supervised Contrastive Loss for 10 epochs followed by fine-tuning with Cross-Entropy Loss for 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and the loss functions\n",
    "model = AlexNet(num_classes=3)\n",
    "model.to(device)\n",
    "contrastive_loss_function = SupervisedContrastiveLoss()\n",
    "cross_entropy_loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training parameters\n",
    "contrastive_epochs = 10\n",
    "cross_entropy_epochs = 5\n",
    "\n",
    "# Training loop for Supervised Contrastive Loss\n",
    "for epoch in range(contrastive_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Training\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = contrastive_loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    # Calculate average losses\n",
    "    avg_train_loss = total_train_loss / train_steps\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Print training progress\n",
    "    print(f'Contrastive Epoch [{epoch+1}/{contrastive_epochs}], Train Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "# Training loop for Cross-Entropy Loss\n",
    "for epoch in range(cross_entropy_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_train_loss = 0\n",
    "    total_valid_loss = 0\n",
    "\n",
    "    # Training\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = cross_entropy_loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()  # Set model to evaluate mode\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = cross_entropy_loss_function(outputs, labels)\n",
    "            total_valid_loss += loss.item()\n",
    "\n",
    "    # Calculate average losses\n",
    "    avg_train_loss = total_train_loss / train_steps\n",
    "    avg_valid_loss = total_valid_loss / valid_steps\n",
    "    train_losses.append(avg_train_loss)\n",
    "    valid_losses.append(avg_valid_loss)\n",
    "    \n",
    "    # Print training and validation progress\n",
    "    print(f'Cross-Entropy Epoch [{epoch+1}/{cross_entropy_epochs}], Train Loss: {avg_train_loss:.4f}, Valid Loss: {avg_valid_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Loss and Accuracy Plot for Train & Fine-Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.plot(train_losses,label=\"train\")\n",
    "plt.plot(valid_losses,label=\"validation\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Fine-Tuned Model\n",
    "In this cell, we evaluate the fine-tuned model on the test dataset using our classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
