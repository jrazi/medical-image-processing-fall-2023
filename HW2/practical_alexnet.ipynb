{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center>Intelligent Analysis of Medical Images</center></h3>\n",
    "<h4><center>HW 2: Practical Part</center></h4>\n",
    "<table width='100%' style=\"border: none;\">\n",
    "    <tr style=\"border: none; text-align: center;\">\n",
    "        <td style=\"border: none;\"><h5>Javad Razi</h5></td>\n",
    "        <td style=\"border: none;\"><h5>401204354</h5></td>\n",
    "        <td style=\"border: none;\"><h5>j.razi@outlook.com</h5></td>\n",
    "</table>\n",
    "<hr/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part A**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and Import Libraries\n",
    "In this cell, we will install, and import all the necessary libraries required for the implementation. This includes `torch` for model building and training, `torchvision` for datasets and data transforms, and additional libraries for metrics and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import gdown\n",
    "except:\n",
    "    %pip install gdown\n",
    "    \n",
    "try:\n",
    "    import wandb\n",
    "except:\n",
    "    %pip install wandb\n",
    "try:\n",
    "    import torch\n",
    "except:\n",
    "    %pip install torch\n",
    "\n",
    "try:\n",
    "    import torchvision\n",
    "except:\n",
    "    %pip install torchvision\n",
    "    \n",
    "try:\n",
    "    import pickle\n",
    "except:\n",
    "    %pip install pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tools\\Anaconda3\\envs\\llm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\jrazi\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\projections\\__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists('./datasets'):\n",
    "    os.makedirs('./datasets')\n",
    "\n",
    "# List of file IDs\n",
    "file_ids = ['1i9Ei3QSmPBnYzqknvZPg_6TNsPomxQYG', '1-2cN6EuFQnIM53q1N3MQCVcoid1NPBWk', '1-0bl_TuSM-JQ4nCwAW7ySn3uYMAGlaz4']\n",
    "\n",
    "# Download the files\n",
    "for file_id in file_ids:\n",
    "    url = f'https://drive.google.com/uc?id={file_id}'\n",
    "    output = f'./datasets/{file_id}.pickle'\n",
    "    if not os.path.exists(output):\n",
    "        gdown.download(url, output, quiet=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load The Pickle Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./datasets/train.pickle', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open('./datasets/test.pickle', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "with open('./datasets/validation.pickle', 'rb') as f:\n",
    "    validation_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize W&B (WandB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Offline and Online switches for wandb. Offline for now since we don't want to log anything yet.\n",
    "import os\n",
    "\n",
    "def wandb_off():\n",
    "    os.environ['WANDB_MODE'] = 'online'\n",
    "    os.environ['WANDB_SILENT'] = 'true'\n",
    "\n",
    "def wandb_on():\n",
    "    os.environ['WANDB_MODE'] = 'disabled'\n",
    "    os.environ['WANDB_SILENT'] = 'false'\n",
    "\n",
    "wandb_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The API Key is required to login. If I should've provided my own API key, please let me know and I will provide it ASAP. \n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project='mri-alexnet', entity='jrazi', name='jrazi-alexnet-from-scratch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet Architecture\n",
    "Here we define the AlexNet architecture in PyTorch. We create a class `AlexNet` that inherits from `nn.Module` and define all the layers in the `__init__` method. The `forward` method dictates the data flow through the network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jrazi\\Desktop\\repo\\medical-image-processing-fall-2023\\HW2\\practical_alexnet.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jrazi/Desktop/repo/medical-image-processing-fall-2023/HW2/practical_alexnet.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mAlexNet\u001b[39;00m(nn\u001b[39m.\u001b[39mModule):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jrazi/Desktop/repo/medical-image-processing-fall-2023/HW2/practical_alexnet.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, num_classes\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jrazi/Desktop/repo/medical-image-processing-fall-2023/HW2/practical_alexnet.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39msuper\u001b[39m(AlexNet, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Dataloaders\n",
    "In this cell, we define our custom dataset class which will handle the MRI images. We'll also create the dataloaders for training, validation, and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.data[index]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Define transforms for the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((227, 227)), # AlexNet uses 227x227 inputs\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = MRIDataset(train_data, transform=transform)\n",
    "valid_dataset = MRIDataset(validation_data, transform=transform)\n",
    "test_dataset = MRIDataset(test_data, transform=transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function and Optimizer\n",
    "In this cell, we define the loss function and the optimizer for our AlexNet model. We use Cross-Entropy Loss for our multi-class classification problem and the Adam optimizer with a learning rate of 1e-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet(num_classes=3)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop\n",
    "Here we define the training loop where we train our AlexNet model. We keep track of the loss and accuracy for both the training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jrazi\\Desktop\\repo\\medical-image-processing-fall-2023\\HW2\\practical_alexnet.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jrazi/Desktop/repo/medical-image-processing-fall-2023/HW2/practical_alexnet.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Training parameters\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jrazi/Desktop/repo/medical-image-processing-fall-2023/HW2/practical_alexnet.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jrazi/Desktop/repo/medical-image-processing-fall-2023/HW2/practical_alexnet.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_steps \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_loader)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jrazi/Desktop/repo/medical-image-processing-fall-2023/HW2/practical_alexnet.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m valid_steps \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(valid_loader)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jrazi/Desktop/repo/medical-image-processing-fall-2023/HW2/practical_alexnet.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# To track the training loss as the model trains\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "num_epochs = 10\n",
    "train_steps = len(train_loader)\n",
    "valid_steps = len(valid_loader)\n",
    "\n",
    "# To track the training loss as the model trains\n",
    "train_losses = []\n",
    "# To track the validation loss as the model trains\n",
    "valid_losses = []\n",
    "# To track the average training loss per epoch as the model trains\n",
    "avg_train_losses = []\n",
    "# To track the average validation loss per epoch as the model trains\n",
    "avg_valid_losses = [] \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_train_loss = 0\n",
    "    total_valid_loss = 0\n",
    "\n",
    "    # Training\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "        wandb.log({'train_loss': loss.item()})\n",
    "\n",
    "    # Validation\n",
    "    model.eval()  # Set model to evaluate mode\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            total_valid_loss += loss.item()\n",
    "            wandb.log({'valid_loss': loss.item()})\n",
    "\n",
    "    # Calculate average losses\n",
    "    avg_train_loss = total_train_loss / train_steps\n",
    "    avg_valid_loss = total_valid_loss / valid_steps\n",
    "    train_losses.append(avg_train_loss)\n",
    "    valid_losses.append(avg_valid_loss)\n",
    "    \n",
    "    # Log average losses to wandb\n",
    "    wandb.log({'epoch': epoch, 'avg_train_loss': avg_train_loss, 'avg_valid_loss': avg_valid_loss})\n",
    "\n",
    "    # Print training and validation progress\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Valid Loss: {avg_valid_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation Loss Plots\n",
    "In this cell, we visualize the training and validation loss over the epochs to understand the learning trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.plot(avg_train_losses,label=\"train\")\n",
    "plt.plot(avg_valid_losses,label=\"validation\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Model\n",
    "In this cell, we evaluate the trained AlexNet model on the test dataset and calculate the classification metrics like accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "# Log metrics to wandb\n",
    "wandb.log({'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1_score': f1})\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create wandb metrics\n",
    "\n",
    "from_scratch_metrics = {\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1_score': f1\n",
    "}\n",
    "\n",
    "# Log metrics to wandb for the from-scratch model\n",
    "wandb.log({'from_scratch_accuracy': from_scratch_metrics['accuracy'],\n",
    "           'from_scratch_precision': from_scratch_metrics['precision'],\n",
    "           'from_scratch_recall': from_scratch_metrics['recall'],\n",
    "           'from_scratch_f1_score': from_scratch_metrics['f1_score']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part B**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project='mri-alexnet', entity='jrazi', name='jrazi-alexnet-pretrained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pre-Trained AlexNet\n",
    "In this cell, we load a pre-trained AlexNet model from torchvision's models. We then replace the final classification layer to match the number of classes in our dataset. We'll also define the loss function and optimizer for this pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# Load pre-trained AlexNet\n",
    "pretrained_alexnet = models.alexnet(pretrained=True)\n",
    "# Modify the classifier to match the number of classes\n",
    "pretrained_alexnet.classifier[6] = nn.Linear(pretrained_alexnet.classifier[6].in_features, 3)\n",
    "pretrained_alexnet = pretrained_alexnet.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(pretrained_alexnet.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Validate Pre-Trained AlexNet\n",
    "Here we train and validate the pre-trained AlexNet on our MRI dataset. We track the loss and accuracy for both the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "num_epochs = 10\n",
    "train_steps = len(train_loader)\n",
    "valid_steps = len(valid_loader)\n",
    "\n",
    "# To track the training loss as the model trains\n",
    "pretrained_train_losses = []\n",
    "# To track the validation loss as the model trains\n",
    "pretrained_valid_losses = []\n",
    "# To track the average training loss per epoch as the model trains\n",
    "pretrained_avg_train_losses = []\n",
    "# To track the average validation loss per epoch as the model trains\n",
    "pretrained_avg_valid_losses = [] \n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    pretrained_alexnet.train()  # Set model to training mode\n",
    "    total_train_loss = 0\n",
    "    total_valid_loss = 0\n",
    "\n",
    "    # Training\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = pretrained_alexnet(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    pretrained_alexnet.eval()  # Set model to evaluate mode\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = pretrained_alexnet(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_valid_loss += loss.item()\n",
    "\n",
    "    # Calculate average losses\n",
    "    avg_train_loss = total_train_loss / train_steps\n",
    "    avg_valid_loss = total_valid_loss / valid_steps\n",
    "    pretrained_train_losses.append(avg_train_loss)\n",
    "    pretrained_valid_losses.append(avg_valid_loss)\n",
    "    \n",
    "    # Print training and validation progress\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Valid Loss: {avg_valid_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Loss and Accuracy for Pre-Trained AlexNet\n",
    "We visualize the training and validation loss and accuracy for the pre-trained AlexNet using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.plot(pretrained_avg_train_losses,label=\"train\")\n",
    "plt.plot(pretrained_avg_valid_losses,label=\"validation\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Pre-Trained AlexNet\n",
    "In this cell, we evaluate the pre-trained AlexNet on the test dataset and calculate the classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "pretrained_alexnet.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = pretrained_alexnet(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_metrics = {\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1_score': f1\n",
    "}\n",
    "\n",
    "# Log metrics to wandb for the pre-trained model\n",
    "wandb.log({'pretrained_accuracy': pretrained_metrics['accuracy'],\n",
    "           'pretrained_precision': pretrained_metrics['precision'],\n",
    "           'pretrained_recall': pretrained_metrics['recall'],\n",
    "           'pretrained_f1_score': pretrained_metrics['f1_score']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of From-Scratch and Pre-Trained AlexNet\n",
    "In this cell, we compare the performance of our from-scratch AlexNet with the pre-trained AlexNet on our dataset, based on the metrics we calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\n",
    "    'from_scratch_accuracy': from_scratch_metrics['accuracy'],\n",
    "    'pretrained_accuracy': pretrained_metrics['accuracy'],\n",
    "    'from_scratch_precision': from_scratch_metrics['precision'],\n",
    "    'pretrained_precision': pretrained_metrics['precision'],\n",
    "    'from_scratch_recall': from_scratch_metrics['recall'],\n",
    "    'pretrained_recall': pretrained_metrics['recall'],\n",
    "    'from_scratch_f1_score': from_scratch_metrics['f1_score'],\n",
    "    'pretrained_f1_score': pretrained_metrics['f1_score']\n",
    "})\n",
    "\n",
    "# Print out for inspection\n",
    "print(\"From-Scratch AlexNet Metrics:\")\n",
    "print(f\"Accuracy: {from_scratch_metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {from_scratch_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {from_scratch_metrics['recall']:.4f}\")\n",
    "print(f\"F1-Score: {from_scratch_metrics['f1_score']:.4f}\\n\")\n",
    "\n",
    "print(\"Pre-Trained AlexNet Metrics:\")\n",
    "print(f\"Accuracy: {pretrained_metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {pretrained_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {pretrained_metrics['recall']:.4f}\")\n",
    "print(f\"F1-Score: {pretrained_metrics['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part C**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Supervised Contrastive Loss\n",
    "Here We'll define the new loss function and update our training loop accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.1):\n",
    "        super(SupervisedContrastiveLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        batch_size = features.shape[0]\n",
    "        mask = torch.eye(batch_size).to(features.device)\n",
    "        \n",
    "        # Normalize the features\n",
    "        features = F.normalize(features, dim=1)\n",
    "        \n",
    "        # Compute the similarity matrix\n",
    "        sim_matrix = torch.matmul(features, features.T)\n",
    "        \n",
    "        # Create the positive and negative masks\n",
    "        pos_mask = labels.expand(batch_size, batch_size).eq(labels.expand(batch_size, batch_size).T)\n",
    "        neg_mask = ~pos_mask\n",
    "        \n",
    "        # Compute the loss\n",
    "        pos_sim = sim_matrix[pos_mask & ~mask].view(batch_size, -1)\n",
    "        neg_sim = sim_matrix[neg_mask].view(batch_size, -1)\n",
    "        \n",
    "        pos_loss = torch.sum(-torch.log(F.softmax(pos_sim / self.temperature, dim=1)), dim=1)\n",
    "        neg_loss = torch.sum(torch.log(F.softmax(neg_sim / self.temperature, dim=1)), dim=1)\n",
    "        \n",
    "        loss = pos_loss + neg_loss\n",
    "        return loss.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project='mri-alexnet', entity='jrazi', name='jrazi-alexnet-supervised-contrastive-loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain & Fine-Tune with Categorical Cross-Entropy\n",
    "Here, we retrain the from-scratch AlexNet using Supervised Contrastive Loss for 10 epochs followed by fine-tuning with Cross-Entropy Loss for 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet(num_classes=3)\n",
    "model.to(device)\n",
    "contrastive_loss_function = SupervisedContrastiveLoss()\n",
    "cross_entropy_loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training parameters\n",
    "contrastive_epochs = 10\n",
    "cross_entropy_epochs = 5\n",
    "\n",
    "# Training loop for Supervised Contrastive Loss\n",
    "for epoch in range(contrastive_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Training\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = contrastive_loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "        # Log batch loss\n",
    "        wandb.log({'contrastive_train_loss': loss.item()})\n",
    "\n",
    "    # Calculate average losses\n",
    "    avg_train_loss = total_train_loss / train_steps\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Log average loss to wandb\n",
    "    wandb.log({'epoch': epoch, 'contrastive_avg_train_loss': avg_train_loss})\n",
    "\n",
    "    # Print training progress\n",
    "    print(f'Contrastive Epoch [{epoch+1}/{contrastive_epochs}], Train Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "# Transition to Cross-Entropy Loss training\n",
    "wandb.log({'phase': 'cross_entropy_loss_training'})\n",
    "\n",
    "# Training loop for Cross-Entropy Loss\n",
    "for epoch in range(cross_entropy_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_train_loss = 0\n",
    "    total_valid_loss = 0\n",
    "\n",
    "    # Training\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = cross_entropy_loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "        # Log batch loss\n",
    "        wandb.log({'cross_entropy_train_loss': loss.item()})\n",
    "\n",
    "    # Validation\n",
    "    model.eval()  # Set model to evaluate mode\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = cross_entropy_loss_function(outputs, labels)\n",
    "            total_valid_loss += loss.item()\n",
    "            # Log batch validation loss\n",
    "            wandb.log({'cross_entropy_valid_loss': loss.item()})\n",
    "\n",
    "    # Calculate average losses\n",
    "    avg_train_loss = total_train_loss / train_steps\n",
    "    avg_valid_loss = total_valid_loss / valid_steps\n",
    "    train_losses.append(avg_train_loss)\n",
    "    valid_losses.append(avg_valid_loss)\n",
    "    \n",
    "    # Log average losses to wandb\n",
    "    wandb.log({'epoch': epoch + contrastive_epochs,  # offset by the number of contrastive epochs\n",
    "               'cross_entropy_avg_train_loss': avg_train_loss,\n",
    "               'cross_entropy_avg_valid_loss': avg_valid_loss})\n",
    "\n",
    "    # Print training and validation progress\n",
    "    print(f'Cross-Entropy Epoch [{epoch+1}/{cross_entropy_epochs}], Train Loss: {avg_train_loss:.4f}, Valid Loss: {avg_valid_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Loss and Accuracy Plot for Train & Fine-Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.plot(train_losses,label=\"train\")\n",
    "plt.plot(valid_losses,label=\"validation\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Fine-Tuned Model\n",
    "In this cell, we evaluate the fine-tuned model on the test dataset using our classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "# Log metrics to wandb\n",
    "wandb.log({\n",
    "    'test_accuracy': accuracy,\n",
    "    'test_precision': precision,\n",
    "    'test_recall': recall,\n",
    "    'test_f1_score': f1\n",
    "})\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish the wandb run after evaluation\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
