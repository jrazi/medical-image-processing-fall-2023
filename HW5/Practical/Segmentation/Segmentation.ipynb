{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMIWlsq2wNWS"
      },
      "source": [
        "# **HW5**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7olNe4z1wNWX"
      },
      "source": [
        "In this notebook, our focus is on employing both 2D-UNet and 3D-UNet models to perform segmentation on a set of 30 volumetric medical images. Your task involves completing the designated sections of the notebook and subsequently comparing the outcomes achieved by the 2D and 3D models in terms of segmentation performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqEkX0SCwNWY"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from blocks import *\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-qp2hiUwNWa"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5kkJtA3wNWb"
      },
      "source": [
        "In this step, your objective is to load data from the provided numpy file. Given that the images have varying numbers of slices, your task is to add zero-padded slices to ensure that all images contain a standardized total of 208 slices\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keMbLQDpwR5R"
      },
      "outputs": [],
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1DXe9f_8k2_iPdJsrz2ktMXmMw2G2qPGE' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1DXe9f_8k2_iPdJsrz2ktMXmMw2G2qPGE\" -O dataset.npy && rm -rf /tmp/cookies.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EoQHtUhwNWb"
      },
      "outputs": [],
      "source": [
        "dataset_path = 'dataset.npy'\n",
        "labeled_images = np.load(dataset_path, allow_pickle=True)\n",
        "ORGAN_idx = 6\n",
        "ORGAN = 'liver'\n",
        "image_shape = (128, 128)\n",
        "image_slices = 208\n",
        "\n",
        "data_X = []\n",
        "data_Y = []\n",
        "for idx in range(len(labeled_images)):\n",
        "    xx = labeled_images[idx].get(\"image\")\n",
        "    yy = labeled_images[idx].get(\"label\")\n",
        "\n",
        "    yy[np.where(yy != ORGAN_idx)] = 0\n",
        "    yy[np.where(yy == ORGAN_idx)] = 1\n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "    for i in range(len(xx)):\n",
        "        x.append(cv2.resize(xx[i,:,:], image_shape))\n",
        "        y.append(cv2.resize(yy[i,:,:], image_shape))\n",
        "    x = np.asarray(x)\n",
        "    y = np.asarray(y)\n",
        "\n",
        "    # -------------------------------- YOUR CODE --------------------------------\n",
        "\n",
        "    # -------------------------------- YOUR CODE --------------------------------\n",
        "\n",
        "data_X = np.asarray(data_X)\n",
        "data_Y = np.asarray(data_Y)\n",
        "print(data_X.shape)\n",
        "print(data_Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0J5VyZQwNWc"
      },
      "outputs": [],
      "source": [
        "n_train, n_valid = 20, 10\n",
        "\n",
        "train_X = data_X[:n_train]\n",
        "train_Y = data_Y[:n_train]\n",
        "\n",
        "# valid_X = data_X[:n_train]\n",
        "# valid_Y = data_Y[:n_train]\n",
        "\n",
        "valid_X = data_X[n_train:n_train+n_valid]\n",
        "valid_Y = data_Y[n_train:n_train+n_valid]\n",
        "\n",
        "print(train_X.shape, train_Y.shape)\n",
        "print(valid_X.shape, valid_Y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRdRyV9ewNWe"
      },
      "source": [
        "In the next cell write code to visualize some of the slices randomly from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDEcFrc8wNWf"
      },
      "outputs": [],
      "source": [
        "# -------------------------------- YOUR CODE --------------------------------\n",
        "\n",
        "# -------------------------------- YOUR CODE --------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab8DLINbwNWf"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgGz-pyHwNWf"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AScJdAAwNWg"
      },
      "outputs": [],
      "source": [
        "def pad_to_shape(this, shp):\n",
        "    if len(shp) == 4:\n",
        "        pad = (0, shp[3] - this.shape[3], 0, shp[2] - this.shape[2])\n",
        "    elif len(shp) == 5:\n",
        "        pad = (0, shp[4] - this.shape[4], 0, shp[3] - this.shape[3], 0, shp[2] - this.shape[2])\n",
        "    return F.pad(this, pad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sGu8hVuwNWg"
      },
      "source": [
        "Write a function that computes the dice score between a batch of prediction and ground truths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzUgVKJAwNWh"
      },
      "outputs": [],
      "source": [
        "def dice_score(y_pred_bin, y_true):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        y_pred_bin: shape => (batch_size, 1, h, w)\n",
        "        y_true: shape => (batch_size, 1, h, w)\n",
        "\n",
        "    Returns:\n",
        "        : shape => (batch_size, dice_score)\n",
        "    \"\"\"\n",
        "\n",
        "    # -------------------------------- YOUR CODE --------------------------------\n",
        "\n",
        "    # -------------------------------- YOUR CODE --------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJUYiEVLwNWh"
      },
      "source": [
        "# Part 1: 2D UNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmfOF8VAwNWh"
      },
      "source": [
        "In this section we are going to use a 2D UNet to train a segmentation model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtPvrJRYwNWh"
      },
      "source": [
        "## Part 1.1: Model Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLI4ZjlrwNWh"
      },
      "source": [
        "First we need to implement the model architecture. The necessary modules are created in the init functions. Complete the forward method for the UNet model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rbW3CBhwNWh"
      },
      "outputs": [],
      "source": [
        "class UNet2D(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, conv_depths=(16, 32, 64, 128, 256)):\n",
        "        assert len(conv_depths) > 2, 'conv_depths must have at least 3 members'\n",
        "        super(UNet2D, self).__init__()\n",
        "\n",
        "        # defining encoder layers\n",
        "        encoder_layers = []\n",
        "        encoder_layers.append(First2D(in_channels, conv_depths[0], conv_depths[0]))\n",
        "        encoder_layers.extend([Encoder2D(conv_depths[i], conv_depths[i + 1], conv_depths[i + 1])\n",
        "                               for i in range(len(conv_depths)-2)])\n",
        "\n",
        "        # defining decoder layers\n",
        "        decoder_layers = []\n",
        "        decoder_layers.extend([Decoder2D(2 * conv_depths[i + 1], 2 * conv_depths[i], 2 * conv_depths[i], conv_depths[i])\n",
        "                               for i in reversed(range(len(conv_depths)-2))])\n",
        "        decoder_layers.append(Last2D(conv_depths[1], conv_depths[0], out_channels))\n",
        "\n",
        "        # encoder, center and decoder layers\n",
        "        self.encoder_layers = nn.Sequential(*encoder_layers)\n",
        "        self.center = Center2D(conv_depths[-2], conv_depths[-1], conv_depths[-1], conv_depths[-2])\n",
        "        self.decoder_layers = nn.Sequential(*decoder_layers)\n",
        "\n",
        "    def forward(self, x, return_all=False):\n",
        "\n",
        "        # -------------------------------- YOUR CODE --------------------------------\n",
        "\n",
        "        # -------------------------------- YOUR CODE --------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkcrrwZbwNWi"
      },
      "source": [
        "## Part 1.2: Dataset Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_rxvw1MwNWi"
      },
      "outputs": [],
      "source": [
        "class Dataset2D(Dataset):\n",
        "    def __init__(self, x, y, Normalization = False):\n",
        "\n",
        "        self.Normalization = Normalization\n",
        "        self.slices_x = []\n",
        "        self.slices_y = []\n",
        "        for i in range(x.shape[0]):\n",
        "            for j in range(x.shape[2]):\n",
        "                sx = x[i, :, j, :, :]\n",
        "                sy = y[i, :, j, :, :]\n",
        "                if sy.sum() > 0:\n",
        "                    self.slices_x.append(sx)\n",
        "                    self.slices_y.append(sy)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.slices_x) # number of samples\n",
        "\n",
        "\n",
        "    def __getitem__(self, index): # sampling method. used by DataLoader.\n",
        "        x = self.slices_x[index]\n",
        "        y = self.slices_y[index]\n",
        "        if self.Normalization:\n",
        "            x = (x - x.min()) / (x.max() - x.min())\n",
        "        return x, y, index # we return the index as well for future use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcOJmHLewNWi"
      },
      "source": [
        "## Part 1.3: Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8eF899LwNWi"
      },
      "outputs": [],
      "source": [
        "model = UNet2D(in_channels=1, out_channels=2)\n",
        "model.to(device).float()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-1)\n",
        "epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40nMP04ZwNWj"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "    Dataset2D(train_X, train_Y, Normalization=True),\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=6\n",
        ")\n",
        "\n",
        "print('Train Loader Done')\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "    Dataset2D(valid_X, valid_Y, Normalization=True),\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=6\n",
        ")\n",
        "\n",
        "print('Validation Loader Done')\n",
        "\n",
        "samples_count = len(train_loader.dataset)\n",
        "val_samples_count = len(valid_loader.dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Toxx55UPwNWj"
      },
      "source": [
        "The necesary components are created. Now write the training loop and train your model. Report validation results during training and save the training log in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkXANA00wNWj"
      },
      "outputs": [],
      "source": [
        "# -------------------------------- YOUR CODE --------------------------------\n",
        "\n",
        "# -------------------------------- YOUR CODE --------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC1e6_F-wNWk"
      },
      "source": [
        "# Part 2: 3D UNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hbb6TPLwNWl"
      },
      "source": [
        "Now we want to use a 3D model and see if we can get better results. Complete the specified parts and train the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTipeOk_wNWl"
      },
      "source": [
        "## Part 2.1: Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mIxRvKwwNWl"
      },
      "outputs": [],
      "source": [
        "class UNet3D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, conv_depths=(16, 32, 64, 128, 256)):\n",
        "        assert len(conv_depths) > 2, 'conv_depths must have at least 3 members'\n",
        "\n",
        "        super(UNet3D, self).__init__()\n",
        "\n",
        "        # defining encoder layers\n",
        "        encoder_layers = []\n",
        "        encoder_layers.append(First3D(in_channels, conv_depths[0], conv_depths[0]))\n",
        "        encoder_layers.extend([Encoder3D(conv_depths[i], conv_depths[i + 1], conv_depths[i + 1])\n",
        "                               for i in range(len(conv_depths)-2)])\n",
        "\n",
        "        # defining decoder layers\n",
        "        decoder_layers = []\n",
        "        decoder_layers.extend([Decoder3D(2 * conv_depths[i + 1], 2 * conv_depths[i], 2 * conv_depths[i], conv_depths[i])\n",
        "                               for i in reversed(range(len(conv_depths)-2))])\n",
        "        decoder_layers.append(Last3D(conv_depths[1], conv_depths[0], out_channels))\n",
        "\n",
        "        # encoder, center and decoder layers\n",
        "        self.encoder_layers = nn.Sequential(*encoder_layers)\n",
        "        self.center = Center3D(conv_depths[-2], conv_depths[-1], conv_depths[-1], conv_depths[-2])\n",
        "        self.decoder_layers = nn.Sequential(*decoder_layers)\n",
        "\n",
        "    def forward(self, x, return_all=False):\n",
        "\n",
        "        # -------------------------------- YOUR CODE --------------------------------\n",
        "\n",
        "        # -------------------------------- YOUR CODE --------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsyhD-9_wNWm"
      },
      "source": [
        "## Part 2.2: Dataset Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBvAdjiKwNWm"
      },
      "outputs": [],
      "source": [
        "class Dataset3D(Dataset):\n",
        "    def __init__(self, x, y, Normalization = False):\n",
        "\n",
        "        self.Normalization = Normalization\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x) # number of samples\n",
        "\n",
        "\n",
        "    def __getitem__(self, index): # sampling method. used by DataLoader.\n",
        "        x = self.x[index]\n",
        "        y = self.y[index]\n",
        "        if self.Normalization:\n",
        "            x = (x - x.min()) / (x.max() - x.min())\n",
        "        return x, y, index # we return the index as well for future use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSUN2OHswNWm"
      },
      "source": [
        "## Part 2.3: Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpTRDhCxwNWn"
      },
      "outputs": [],
      "source": [
        "model = UNet3D(in_channels=1, out_channels=2)\n",
        "model = model.to(device).float()\n",
        "model.train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJfs5pCdwNWn"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "    Dataset3D(train_X, train_Y, Normalization=True),\n",
        "    batch_size=1,\n",
        "    shuffle=True,\n",
        "    num_workers=6\n",
        ")\n",
        "\n",
        "print('Train Loader Done')\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "    Dataset3D(valid_X, valid_Y, Normalization=True),\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=6\n",
        ")\n",
        "\n",
        "print('Validation Loader Done')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBj1o7DBwNWo"
      },
      "outputs": [],
      "source": [
        "# -------------------------------- YOUR CODE --------------------------------\n",
        "\n",
        "# -------------------------------- YOUR CODE --------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEdh_igwwNWp"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4IF0JHGwNWp"
      },
      "source": [
        "In the final section visualize segmentation masks for a few random slices for both 2D and 3D model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcWp0y2YwNW8"
      },
      "outputs": [],
      "source": [
        "# -------------------------------- YOUR CODE --------------------------------\n",
        "\n",
        "# -------------------------------- YOUR CODE --------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9eqYgbLwNW8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "490iDnTzwNW9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
