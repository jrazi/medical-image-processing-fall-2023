{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-P0TW4-C4sy"
      },
      "source": [
        "##  Covid Image Classification Using ResNet and Inference\n",
        "COVID-19 detection models utilizing CT images involve the application of machine learning algorithms to analyze chest X-ray images, aiming to identify patterns and features associated with COVID-19 infections. The provided [dataset](https://www.kaggle.com/datasets/plameneduardo/a-covid-multiclass-dataset-of-ct-scans/) comprises 4173 CT scan images of the lungs (Chest CT Scan) with three different classes, including Covid, Healthy, and Others. Our focus for this assignment is solely on the first two classes.*italicized text*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN-fF_L7Jrun"
      },
      "source": [
        "### Download the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xVSg03OCB9k"
      },
      "source": [
        "You can download the dataset of this relevant exercise using the code snippet below. Just note that you need to create an account in Kaggle first and then follow the steps below to receive your `kaggle.json` file and then upload it below:\n",
        "1. Go to your Kaggle account, Scroll to the API section, and Click Expire API Token to remove previous tokens\n",
        "2. Click on Create New API Token - It will download the `kaggle.json` file on your machine.\n",
        "\n",
        "If you need more details to read, you can refer to this [link](https://www.kaggle.com/discussions/general/156610).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1GdKcfIJ6rb"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "yz-H645VJ7kJ",
        "outputId": "6c08bb72-99c4-4de7-ba5c-a0c6981f397f"
      },
      "outputs": [],
      "source": [
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "522dWjB1C6fM",
        "outputId": "38485cb0-f005-4fc9-aeba-87771e31fe3e"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aeiXpdsN4Fc",
        "outputId": "9bb51a13-47c8-4967-9827-0aeb3d71ce9f"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets download plameneduardo/a-covid-multiclass-dataset-of-ct-scans/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncdKZsoHMoG7",
        "outputId": "3571f66c-2219-4b06-91bb-618f9f246df0"
      },
      "outputs": [],
      "source": [
        "!unzip ./a-covid-multiclass-dataset-of-ct-scans.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLcHY9LoONWU"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a6xlnW_OPx5"
      },
      "source": [
        "* The existing data structure consists of patient-wise subfolders. Thus, the initial step involves copying all images into the Covid, Healthy, and Other folders while eliminating any subfolders.\n",
        "\n",
        "* Count the data in each class to determine if there is an imbalance issue or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdMtY_GuF8_A"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import utils\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.util import random_noise\n",
        "from skimage.filters import gaussian\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.optim import SGD\n",
        "import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onh6DGCwAhLO"
      },
      "source": [
        " Creating ./data with its subfolders, splitting the files, and saving each file to its respective directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6G7DqK_5GJhc"
      },
      "outputs": [],
      "source": [
        "!mkdir ./data\n",
        "!mkdir ./data/train\n",
        "!mkdir ./data/test\n",
        "!mkdir ./data/train/covid\n",
        "!mkdir ./data/train/healthy\n",
        "!mkdir ./data/test/covid\n",
        "!mkdir ./data/test/healthy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngzX1t4hEsrL"
      },
      "outputs": [],
      "source": [
        "def copyfiles(source, dest):\n",
        "    file_names = []\n",
        "    for foldername, subfolders, filenames in os.walk(source):\n",
        "        for filename in filenames:\n",
        "            file_path = os.path.join(foldername, filename)\n",
        "            file_names.append(file_path)\n",
        "\n",
        "    train_files, test_files = train_test_split(file_names, test_size=0.2, random_state=42)\n",
        "    for file_path in train_files:\n",
        "        shutil.copy(file_path, os.path.join('./data/train' + dest, os.path.basename(file_path)))\n",
        "    for file_path in test_files:\n",
        "        shutil.copy(file_path, os.path.join('./data/test' + dest, os.path.basename(file_path)))\n",
        "\n",
        "copyfiles('./New_Data_CoV2/Covid', '/covid')\n",
        "copyfiles('./New_Data_CoV2/Healthy', '/healthy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZwt_SYUxTOk",
        "outputId": "ac40b34c-db73-4307-cd9c-2be055bafbc7"
      },
      "outputs": [],
      "source": [
        "def count_files(directory_path):\n",
        "    file_count = 0\n",
        "    for root, dirs, files in os.walk(directory_path):\n",
        "        file_count += len(files)\n",
        "    return file_count\n",
        "\n",
        "print('The total number of files in trainset:',  count_files('./data/train/'))\n",
        "print('The total number of files in testset:',  count_files('./data/test/'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwm-2mPvP_cR"
      },
      "source": [
        "Visualize the dataset and plot some randomly selected sample images from the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "SqDw1uNHQH8a",
        "outputId": "53ca982c-5961-4c84-d4d1-fbfa058bdea9"
      },
      "outputs": [],
      "source": [
        "def plot_images_in_row(folder_path, num_images=4):\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    selected_images = random.sample(image_files, min(num_images, len(image_files)))\n",
        "    plt.figure(figsize=(15, 3))\n",
        "\n",
        "    for i, image_file in enumerate(selected_images, start=1):\n",
        "        plt.subplot(1, num_images, i)\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        img = mpimg.imread(image_path)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "covid_folder = './data/train/covid'\n",
        "healthy_folder = './data/train/healthy'\n",
        "\n",
        "plot_images_in_row(healthy_folder)\n",
        "plot_images_in_row(covid_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1gzMaoJCKzR"
      },
      "source": [
        "Create data loaders and apply preprocessing techniques, as well as augmentation and transformation methods, to enhance the model's performance. Also, split the data into train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoD96mc5Nrbb",
        "outputId": "9f5a219e-e904-4c6d-a7ef-f7332d3a035d"
      },
      "outputs": [],
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "covid_train = os.listdir('./data/train/covid')\n",
        "healthy_train = os.listdir('./data/train/healthy')\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root='./data/train', transform=transform_train)\n",
        "test_dataset = datasets.ImageFolder(root='./data/test', transform=transform_test)\n",
        "\n",
        "class_counts = [covid_train, healthy_train]\n",
        "total_samples = sum(map(len, class_counts))\n",
        "class_freq = [len(class_sample) / total_samples for class_sample in class_counts]\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-IaIquSChxa"
      },
      "source": [
        "### ResNet\n",
        "\n",
        "* Define your model here. You don't need to code it from scratch, and you can also utilize transfer learning if you believe it would enhance your model's performance.\n",
        "\n",
        "* If a class imbalance problem exists, recommend a solution and implement it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuVTpC_ZStWu"
      },
      "outputs": [],
      "source": [
        "resnet_model = models.resnet18(pretrained=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_features = resnet_model.fc.in_features\n",
        "resnet_model.fc = nn.Linear(num_features, 2)\n",
        "resnet_model = resnet_model.to(device)\n",
        "\n",
        "class_weights = torch.FloatTensor([1.0 / freq for freq in class_freq]).to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "optimizer = optim.Adam(resnet_model.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHkA7DHdVpBk"
      },
      "outputs": [],
      "source": [
        "def fit_model(epochs, model, criterion, optimizer, Train, Test):\n",
        "\n",
        "    train_acc, train_loss = [], []\n",
        "    test_acc, test_loss = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_acc, epoch_loss = 0, 0\n",
        "        model = model.train()\n",
        "\n",
        "        with tqdm.tqdm(enumerate(Train), total=len(Train)) as pbar:\n",
        "            for i, (images, labels) in pbar:\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                output = model(images)\n",
        "                optimizer.zero_grad()\n",
        "                loss = criterion(output, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.detach().item()\n",
        "                _, pred = output.data.topk(1, dim=1)\n",
        "                epoch_acc += (pred.t() == labels).sum().item()\n",
        "\n",
        "        train_loss.append(epoch_loss/(i+1))\n",
        "        train_acc.append(epoch_acc/len(Train.dataset))\n",
        "\n",
        "        print('Epoch: %d | Loss: %.4f | Train Accuracy: %.4f' \\\n",
        "          %(epoch, epoch_loss/(i+1), epoch_acc/len(Train.dataset)))\n",
        "\n",
        "        epoch_acc, epoch_loss = 0, 0\n",
        "        model.eval()\n",
        "\n",
        "        with tqdm.tqdm(enumerate(Test), total=len(Test)) as pbar:\n",
        "            for i, (images, labels) in pbar:\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                output = model(images)\n",
        "                loss = criterion(output, labels)\n",
        "\n",
        "                epoch_loss += loss.detach().item()\n",
        "                _, pred = output.data.topk(1, dim=1)\n",
        "\n",
        "                epoch_acc += (pred.t() == labels).sum().item()\n",
        "\n",
        "        test_loss.append(epoch_loss/(i+1))\n",
        "        test_acc.append(epoch_acc/len(Test.dataset))\n",
        "\n",
        "        print('Epoch: %d | Loss: %.4f | Test Accuracy: %.4f' \\\n",
        "          %(epoch, epoch_loss/(i+1), epoch_acc/len(Test.dataset)))\n",
        "\n",
        "    return train_loss, train_acc, test_loss, test_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhudNxjKUFQD",
        "outputId": "91c750f6-207b-4192-eb34-cff467d02f2a"
      },
      "outputs": [],
      "source": [
        "epochs = 40\n",
        "train_loss , train_acc, test_loss, test_acc = fit_model(epochs, resnet_model,\n",
        "                                                        criterion, optimizer,\n",
        "                                                        train_loader, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT9E1Q8CCxVf"
      },
      "source": [
        "Plot Accuracy and Loss plots for both training and validation parts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "3FQdzDYO4AVJ",
        "outputId": "f57bba98-27b9-467a-e87e-fc85c204cc12"
      },
      "outputs": [],
      "source": [
        "epochs = range(1, epochs + 1)\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_loss, label='Train Loss', marker='o')\n",
        "plt.plot(epochs, test_loss, label='Test Loss', marker='o')\n",
        "plt.title('Training and Testing Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, train_acc, label='Train Accuracy', marker='o')\n",
        "plt.plot(epochs, test_acc, label='Test Accuracy', marker='o')\n",
        "plt.title('Training and Testing Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoNEbbiRDALQ"
      },
      "source": [
        "### Interpretability\n",
        "Here, we aim to select an interpretability algorithm that aids in comprehending the model's decision-making process, debugging, and explaining predictions to non-technical stakeholders. Let's opt for the [Grad-CAM](https://arxiv.org/abs/1610.02391) technique. Grad-CAM, short for Gradient-weighted Class Activation Mapping, highlights important regions in an image that contribute to the model's prediction. This is achieved by computing the gradients of the target class with respect to the final convolutional layer. First, explain about this method and how it works, then implement this technique and visualize the resulting heatmaps.\n",
        "\n",
        "[GradCam github](https://github.com/jacobgil/pytorch-grad-cam)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAjlwOvGMckz"
      },
      "source": [
        "**Your Answer (10 points)**:\n",
        "\n",
        "...\n",
        "\n",
        "...\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_q7htbxMtgK"
      },
      "source": [
        "**GradCam usage (60 points)**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3wBVreMNvbZ"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "  Initially, it is crucial to ensure that the model is in Evaluation mode.\n",
        "  Failing to do so during result verification could inadvertently alter the\n",
        "  model's weights, leading to inaccurate and unreliable results.\n",
        "'''\n",
        "resnet_model.eval()\n",
        "device = \"cpu\"\n",
        "resnet_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9xqR_3SQDqs"
      },
      "source": [
        "Within this section, leverage GradCam to create a function that generates a plot for a given image address. The function should display the image and overlay a heatmap (which was generated by GradCam) on it in a separate plot. **For this, use the 4th layer of your trained Resent**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SV-IITQi-hRl"
      },
      "outputs": [],
      "source": [
        "def plot_GradCam(image_path):\n",
        "    # TODO\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5BaK_y9Gbp2"
      },
      "source": [
        "Visualize GradCAM heatmaps for 10 images and interpret your model's performance and identify areas your model is paying attention to based on the GradCAM output. For this, use the function you wrote in the previous section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhbckCziGcU-"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMtK338nWQZ2"
      },
      "source": [
        "Now, envision that we have trained a neural network, obtained heatmaps, and achieved a model performance of 95%. Despite utilizing Grad-CAM, the heatmaps reveal a consistent focus on the corners, evident across numerous images. In your perspective, what could be the underlying problem, and how might we address and overcome this issue?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbtpcGmENKHJ"
      },
      "source": [
        "**Your Answer (10 points)**:\n",
        "\n",
        "...\n",
        "\n",
        "...\n",
        "\n",
        "..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
