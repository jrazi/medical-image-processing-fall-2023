{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##  Covid Image Classification Using ResNet and Inference\n",
        "COVID-19 detection models utilizing CT images involve the application of machine learning algorithms to analyze chest X-ray images, aiming to identify patterns and features associated with COVID-19 infections. The provided dataset comprises 4173 CT scan images of the lungs (Chest CT Scan) with three different classes, including Covid, Healthy, and Others. Our focus for this assignment is solely on the first two classes.*italicized text*"
      ],
      "metadata": {
        "id": "A-P0TW4-C4sy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the Dataset"
      ],
      "metadata": {
        "id": "aN-fF_L7Jrun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can download the dataset from this [link](https://www.kaggle.com/datasets/plameneduardo/a-covid-multiclass-dataset-of-ct-scans/). You can also download it using the following steps, explained in this [link](https://www.kaggle.com/discussions/general/156610).\n"
      ],
      "metadata": {
        "id": "4xVSg03OCB9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "522dWjB1C6fM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download plameneduardo/a-covid-multiclass-dataset-of-ct-scans/"
      ],
      "metadata": {
        "id": "4aeiXpdsN4Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ./a-covid-multiclass-dataset-of-ct-scans.zip"
      ],
      "metadata": {
        "id": "ncdKZsoHMoG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "eLcHY9LoONWU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The existing data structure consists of patient-wise subfolders. Thus, the initial step involves copying all images into the Covid, Healthy, and Other folders while eliminating any subfolders.\n",
        "\n",
        "* Count the data in each class to determine if there is an imbalance issue or not."
      ],
      "metadata": {
        "id": "6a6xlnW_OPx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "sdMtY_GuF8_A"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Creating ./data with its subfolders, splitting the files, and saving each file to its respective directory."
      ],
      "metadata": {
        "id": "onh6DGCwAhLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ./data\n",
        "\n",
        "# TODO"
      ],
      "metadata": {
        "id": "6G7DqK_5GJhc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def copyfiles(source, dest):\n",
        "\n",
        "    # TODO"
      ],
      "metadata": {
        "id": "ngzX1t4hEsrL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_files(directory_path):\n",
        "\n",
        "    # TODO"
      ],
      "metadata": {
        "id": "rZwt_SYUxTOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the dataset and plot some randomly selected sample images from the data."
      ],
      "metadata": {
        "id": "Qwm-2mPvP_cR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images(folder_path, num_images=4):\n",
        "\n",
        "    # TODO"
      ],
      "metadata": {
        "id": "SqDw1uNHQH8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create data loaders and apply preprocessing techniques, as well as augmentation and transformation methods, to enhance the model's performance. Also, split the data into train and test sets."
      ],
      "metadata": {
        "id": "M1gzMaoJCKzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "      # TODO\n",
        "])\n",
        "\n",
        "# TODO\n",
        "\n",
        "train_loader = ...\n",
        "test_loader = ..."
      ],
      "metadata": {
        "id": "WoD96mc5Nrbb"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet\n",
        "\n",
        "* Define your model here. You don't need to code it from scratch, and you can also utilize transfer learning if you believe it would enhance your model's performance.\n",
        "\n",
        "* If a class imbalance problem exists, recommend a solution and implement it."
      ],
      "metadata": {
        "id": "J-IaIquSChxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = models.resnet18(pretrained=True)"
      ],
      "metadata": {
        "id": "tuVTpC_ZStWu"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "lnJ1PhVmCgRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_model(epochs, model, optimizer, Train, Test):\n",
        "    # TODO\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # TODO\n",
        "\n",
        "    return train_loss, train_acc, test_loss, test_acc\n",
        ""
      ],
      "metadata": {
        "id": "QHkA7DHdVpBk"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 40\n",
        "train_loss , train_acc, test_loss, test_acc = fit_model(epochs, resnet_model, optimizer, train_loader, test_loader)"
      ],
      "metadata": {
        "id": "uhudNxjKUFQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Accuracy and Loss plots for both training and validation parts."
      ],
      "metadata": {
        "id": "ZT9E1Q8CCxVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n"
      ],
      "metadata": {
        "id": "3FQdzDYO4AVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretability\n",
        "Here, we aim to select an interpretability algorithm that aids in comprehending the model's decision-making process, debugging, and explaining predictions to non-technical stakeholders. Let's opt for the [Grad-CAM](https://arxiv.org/abs/1610.02391) technique. Grad-CAM, short for Gradient-weighted Class Activation Mapping, highlights important regions in an image that contribute to the model's prediction. This is achieved by computing the gradients of the target class with respect to the final convolutional layer. First, explain about this method and how it works, then implement this technique and visualize the resulting heatmaps. You can use library functions like tf-explain for this purpose.\n",
        "\n",
        "[https://arxiv.org/abs/1610.02391](https://arxiv.org/abs/1610.02391)\n",
        "\n",
        "[https://github.com/jacobgil/pytorch-grad-cam](https://github.com/jacobgil/pytorch-grad-cam)"
      ],
      "metadata": {
        "id": "PoNEbbiRDALQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_GradCam(image_path):\n",
        "\n",
        "    # TODO"
      ],
      "metadata": {
        "id": "SV-IITQi-hRl"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = './data/train/covid/19.png'\n",
        "plot_GradCam(image_path)"
      ],
      "metadata": {
        "id": "5A0gu8FNexw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize GradCAM heatmaps for 10 images and interpret your model's performance, identifying the areas to which your model is paying attention based on the GradCAM output results."
      ],
      "metadata": {
        "id": "EYMXk4yxnnPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "vv0iLVW8nnf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, envision that we have trained a neural network, obtained heatmaps, and achieved a model performance of 95%. Despite utilizing Grad-CAM, the heatmaps reveal a consistent focus on the corners, evident across numerous images. In your perspective, what could be the underlying problem, and how might we address and overcome this issue?"
      ],
      "metadata": {
        "id": "iMtK338nWQZ2"
      }
    }
  ]
}